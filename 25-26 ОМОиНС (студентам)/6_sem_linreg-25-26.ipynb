{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSHI7j-Q28j3"
   },
   "source": [
    "# Семинар: Линейная регрессия\n",
    "\n",
    "### План семинара\n",
    "1. Линейная модель\n",
    "2. Предоработка данных (заполнение пропусков, преобразование нечисловых признаков, масштабирование, генерация новых признаков)\n",
    "3.  Измерение ошибки в задачах регрессии\n",
    "4. Обучение линейных моделей \n",
    "5. Линейная регрессия и переобучение\n",
    "\n",
    "### Данные об автомобилях (см. 5_sem)\n",
    "\n",
    "Для демонстраций загрузим набор данных [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/Automobile). В данных присутствуют категориальные, целочисленные и вещественнозначные признаки (__последняя колонка - стоимость автомобией__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:18.632809Z",
     "start_time": "2023-03-01T13:28:17.310820Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "#plt.rcParams[\"figure.figsize\"] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:19.621631Z",
     "start_time": "2023-03-01T13:28:18.633845Z"
    },
    "id": "u30Ou_XY28j5"
   },
   "outputs": [],
   "source": [
    "X_raw = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\",\n",
    "    header=None,\n",
    "    na_values=[\"?\"],\n",
    ")\n",
    "\n",
    "y = X_raw[25]\n",
    "#матрица \"объекты-признаки\"\n",
    "X_raw = X_raw.drop(25, axis=1)\n",
    "\n",
    "X_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Линейная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем рассматривать __задачу регрессии__.\n",
    "\n",
    "Пусть \n",
    "$X^l = \\{(x_i, y_i)\\}_{i=1}^l$ - обучающая выборка,\n",
    "$y_i$ - значение целевой переменной, $a$ — модель, $a(x_i)$ — прогноз модели на объекте $x_i$. \n",
    "\n",
    "$$a(x_i)=  w_0+w_1x_i^1+...+w_dx_i^d$$ \n",
    "\n",
    "-- __линейная модель__,\n",
    "где $w_0, w_1,w_2,...,w_d$ - __веса__ признаков (коэффициенты), $w_0$ - __сдвиг__ (bias). \n",
    "\n",
    "Другая форма записи линейной модели:\n",
    "\n",
    "$$a(x_i)=w_0 + \\sum_{j=1}^d w_j x_i^j =  w_0+<w,x_i>, $$ \n",
    "\n",
    "где $w=(w_1,w_2,...,w_d)$ - вектор весов, $<w,x_i>$ - скалярное произведение. ).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__В линейной модели предполагается__ конкретный вид зависимости, а именно, что каждый признак линейно\n",
    "влияет на целевую переменную, и что целевая переменная не зависит от каких-либо\n",
    "комбинаций признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вид линейной модели и области ее применимости требуют, чтобы данные были специальным образом подготовлены для того, чтобы линейная модель оказалась адекватной решаемой задаче. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка данных:\n",
    "\n",
    "1. Закодировать категориальные признаки.\n",
    "2. Обработать NaN.\n",
    "\n",
    "\n",
    "3. Масштабирование.\n",
    "4. Убрать линейную зависимость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заполнение пропусков (повторение см. 5_sem)\n",
    "В матрице объекты-признаки могут быть пропущенные значения, и это вызовет исключение при попытке передать такую матрицу в функцию обучения модели или даже предобработки. Если пропусков немного, можно удалить объекты с пропусками из обучающей выборки. Заполнить пропуски можно разными способами:\n",
    "* заполнить средними (mean, median);\n",
    "* предсказывать пропущенные значения по непропущенным.\n",
    "\n",
    "Часто используют первый вариант - он проще. Для заполнения константами можно использовать метод датафрейма `fillna`, для замены средними — класс `impute.SimpleImputer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Any` возвратит True, если хотя бы один элемент в столбце `True`   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#узнать: есть или нет пропуски в столбце\n",
    "#X_raw.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#число пропусков в каждом столбце\n",
    "X_raw.isnull().sum()\n",
    "#any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Заполним пропуски средними (вещественнозначные признаки) и пустыми строками (категориальные признаки) (повторение см. 5_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:19.632940Z",
     "start_time": "2023-03-01T13:28:19.626525Z"
    },
    "id": "xHXo8yny28j_"
   },
   "outputs": [],
   "source": [
    "# создаем маску, указывающую на столбцы с категориальными признаками\n",
    "cat_features_mask = (X_raw.dtypes == \"object\").values\n",
    "\n",
    "# для вещественнозначных признаков заполним пропуски средними\n",
    "X_real = X_raw[X_raw.columns[~cat_features_mask]]\n",
    "\n",
    "mis_replacer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "X_no_mis_real = pd.DataFrame(\n",
    "    data=mis_replacer.fit_transform(X_real), columns=X_real.columns\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_mis_real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для категориальных — пустыми строками\n",
    "X_cat = X_raw[X_raw.columns[cat_features_mask]].fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_mis_real.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_mis = pd.concat([X_no_mis_real, X_cat], axis=1)\n",
    "X_no_mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.get_dummies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNoCS3EK28kR"
   },
   "source": [
    "### Преобразуем нечисловые признаки при помощи one-hot encoding (повторение см. 5_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:19.730659Z",
     "start_time": "2023-03-01T13:28:19.634185Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "hLiNNMYz28kc",
    "outputId": "71635d35-f724-43d8-9244-cb83af917b0a"
   },
   "outputs": [],
   "source": [
    "X_dum = pd.get_dummies(X_no_mis, drop_first=True, dtype=float)\n",
    "print(f\"Data shape: {X_dum.shape}\")\n",
    "X_dum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaZ_SxAP28kf"
   },
   "source": [
    "### Масштабирование признаков с помощью MinMaxScaler (повторение см. 5_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:19.751117Z",
     "start_time": "2023-03-01T13:28:19.662833Z"
    },
    "id": "jNymKr5D28kh"
   },
   "outputs": [],
   "source": [
    "normalizer = MinMaxScaler()\n",
    "X_real_norm_np = normalizer.fit_transform(X_dum.values)\n",
    "X = pd.DataFrame(data=X_real_norm_np)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbwg7jRv28kn"
   },
   "source": [
    "### Добавление признаков\n",
    "__Важным моментом для линейной регрессии__ является нелинейное преобразование признаков. Это позволяет использовать линейную регрессию для моделирования нелинейных зависимостей.\n",
    "\n",
    "Наиболее популярны такие преобразования:\n",
    "- добавление полиномиальных признаков (`PolynomialFeatures` в sklearn)\n",
    "- взятие логарифма признака\n",
    "- взятие квадратного корня\n",
    "- применение тригонометрических функций\n",
    "\n",
    "Небольшой пример. Посмотрев на наши данные, мы можем заметить, что зависимость целевой переменной от шестого признака скорее квадратичная, чем линейная:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.019803Z",
     "start_time": "2023-03-01T13:28:19.691057Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Bv0qZAP028kr",
    "outputId": "c1fbdef3-0154-4870-d258-1b46177dc96d"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[6], y)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.046235Z",
     "start_time": "2023-03-01T13:28:19.871417Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "In7bi4a728ku",
    "outputId": "d01a472e-d0e9-446a-f011-2944ef6fdb65"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[6] ** 2, y)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#можно так преобразовать\n",
    "#plt.scatter(X[6], np.sqrt(y))\n",
    "#plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LLqJaxF28kw"
   },
   "source": [
    "А для признака номер 13 линеаризовать зависимость получается с помощью функции $\\frac 1 {\\sqrt{x}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.212335Z",
     "start_time": "2023-03-01T13:28:20.043706Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Ff2MqK_U28kx",
    "outputId": "ca370ede-de10-4c7c-f0cb-5fdf1a7717c9"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[13], y)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.403012Z",
     "start_time": "2023-03-01T13:28:20.219174Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "6MhgQI3p28kz",
    "outputId": "444da03b-f69c-41f3-98d8-f96105777bc8"
   },
   "outputs": [],
   "source": [
    "plt.scatter(1 / np.sqrt(X[13]), y)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPqAUdTR28k1"
   },
   "source": [
    "## 3.  Измерение ошибки в задачах регрессии\n",
    "\n",
    "Итак, $y$ - значение целевой переменной, $a$ — модель. \n",
    "\n",
    "$a(x_i)=  w_0+w_1x_i^1+...+w_dx_i^d$\n",
    "-- __линейная модель__,\n",
    "где $w_0, w_1,w_2,...,w_d$ -- веса признаков, $l$ - число объектов, $d$ - число признаков.\n",
    "\n",
    "Чтобы обучать регрессионные модели, нужно определиться, как именно измеряется качество предсказаний.\n",
    "Важно контролировать качество предсказаний во время обучения, после обучения на новых данных, а также сравнивать качество предсказаний разных двух моделей.\n",
    "\n",
    "Рассмотрим несколько способов оценить отклонение $L(y, a)$ прогноза от истинного ответа.   \n",
    "$L(y, a)$ называют <u>функцией потерь</u>, задающей <u>штраф</u> за разницу между предсказанием и истинным значением целевого признака. Свойства функции потерь:\n",
    "* $L(y_i, a(x_i)) \\geqslant 0$;\n",
    "* $L(y_i, y_i) = 0$.\n",
    "\n",
    "\n",
    "\n",
    "<u>Функционал качества</u> (<u>функционал ошибки</u>) в задачах обучения с учителем обычно задается в виде суммы по объектам выборки:\n",
    "$$Q(a) = \\frac 1 \\ell \\sum_{i=1}^\\ell L(y_i, a(x_i))$$\n",
    "\n",
    "__Пример:__ если мы не различаем маленькие ошибки (между 0.01 и 0.1 нет особой разницы) и не хотим получать большие ошибки, можно использовать следующую функцию потерь:\n",
    "\n",
    "$$L(y_i, a(x_i)) = [| y_i - a(x_i) | < \\varepsilon],$$ $\\varepsilon$ — допустимая разница между предсказанием и фактом.\n",
    "\n",
    "### MSE (Mean Squared Error)\n",
    "\n",
    "$L(y_i, a(x_i)) = (a(x_i) - y_i)^2$\n",
    "\n",
    "Эта функция наиболее часто используется в задачах регрессии.\n",
    "\n",
    "__Среднеквадратичная ошибка (Mean Squared Error, MSE)__: \n",
    "\n",
    "$$MSE (a, X) = \\frac{1}{l}\\sum^l_{i=1}(a(x_i) - y_i)^2$$\n",
    "\n",
    "MSE не обладает свойством устойчивости к __выбросам__ (значение целевой переменной на них либо ошибочно, либо относится к другому распределению и должно быть проигнорировано) потому что задает очень большие штрафы за большие отклонения от фактического значения.\n",
    "\n",
    "**Пример**. Выберем признак (имеющий индекс 7 в матрице X) и целевой признак (имеющий индекс 15 в матрице X). Добавим к полученной выборке два объекта-выброса и посмотрим, как изменится оптимизированная на MSE прямая.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression #про линейную регрессию будет ниже "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Будем предсказывать признак 15 по признаку 7\n",
    "X_subset = X[[7, 15]].values\n",
    "X_subset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[15].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.408064Z",
     "start_time": "2023-03-01T13:28:20.406047Z"
    },
    "id": "JVmJjuUU28k7"
   },
   "outputs": [],
   "source": [
    "#добавление двух шумовых точек (двух выбросов)\n",
    "X_subset_modified = np.vstack((X_subset, [[1, 90], [2, 50]])) \n",
    "X_subset_modified[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(X[15]==0).sum()\n",
    "#(X[15]==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.414752Z",
     "start_time": "2023-03-01T13:28:20.413043Z"
    },
    "id": "jNZJOsJp28k9"
   },
   "outputs": [],
   "source": [
    "#функция для отрисовки данных\n",
    "def scatter_points_and_plot_line_MSE(\n",
    "    X_subset: np.array, ax: matplotlib.axes._axes.Axes\n",
    ") -> None:\n",
    "    # визуализируем точки (признак - таргет)\n",
    "    ax.scatter(X_subset[:, 0], X_subset[:, 1])\n",
    "\n",
    "    # обучим линейную модель (обычная линейная регрессия)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_subset[:, 0][:, np.newaxis], X_subset[:, 1])\n",
    "\n",
    "    # визуализируем прямую\n",
    "    grid = np.linspace(0, 2, 100) #точки по оси x\n",
    "    line = lr.predict(grid[:, np.newaxis]) #предсказанные значения \n",
    "    ax.plot(grid, line) \n",
    "    ax.set_ylim(-20, 100)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.750785Z",
     "start_time": "2023-03-01T13:28:20.419014Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "EurNOGcA28k_",
    "outputId": "a0a4b098-838b-4f81-9796-b6fb5f1d80eb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "ax[0].set_title(\"MSE without outliers\") #без выбросов\n",
    "scatter_points_and_plot_line_MSE(X_subset, ax[0])\n",
    "ax[1].set_title(\"MSE with outliers\")   #с выбросами\n",
    "scatter_points_and_plot_line_MSE(X_subset_modified, ax[1])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6JR5Gxq8ZcZ"
   },
   "source": [
    "**Задание.** Реализуйте функцию для подсчета MSE с использованием numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.756022Z",
     "start_time": "2023-03-01T13:28:20.752982Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1mp3T5y844J",
    "outputId": "8bec51dd-6f89-4b1a-9653-9964ca0e4c34"
   },
   "outputs": [],
   "source": [
    "def MSE(y: np.array, y_pred: np.array) -> np.float64:\n",
    "    # <YOUR CODE HERE>\n",
    "    return ((y-y_pred)**2).mean()\n",
    "\n",
    "\n",
    "a = np.array([11, 20, 19, 17, 10])\n",
    "pred = np.array([12, 18, 19.5, 18, 9])\n",
    "mse = MSE(y=a, y_pred=pred)\n",
    "print(f\"Mean Square Error is: {mse}\")\n",
    "assert mse == 1.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альтернативный вариант (sklearn):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean Square Error is: {mean_squared_error(a, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_squared_error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Примечание__. Если использовать MSE как функционал качества (для обучения), то в формуле для MSE на $l$ можно не делить.\n",
    "Если использовать MSE как метрику качества (для оценки качества модели), то в формуле для MSE нужно деление на $l$, и лучше\n",
    "извлекать корень из MSE, т.е. иcпользовать метрику RMSE.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoNn7V3VAxH7"
   },
   "source": [
    "### RMSE (Root Mean Square Error)\n",
    "\n",
    "Для лучшей интерпретации используется __Root Mean Square Error (RMSE)__: её значение имеет те же масштабы, что и целевая переменная.\n",
    "\n",
    "$$RMSE (a, X) = \\sqrt{MSE (a, X)} = \\sqrt{ \\sum^l_{i=1}(a(x_i) - y_i)^2}$$\n",
    "\n",
    "**Задание.** Реализуйте функцию для подсчета RMSE с использованием numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.764523Z",
     "start_time": "2023-03-01T13:28:20.760760Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IowhU6p1Cj47",
    "outputId": "4c63cf61-4097-4488-f889-8a8c8eb777c6"
   },
   "outputs": [],
   "source": [
    "def RMSE(y: np.array, y_pred: np.array) -> np.float64:\n",
    "    # <YOUR CODE HERE>\n",
    "    return np.sqrt(MSE(y,y_pred))\n",
    "\n",
    "rmse = RMSE(y=a, y_pred=pred)\n",
    "print(f\"Root Mean Square Error is: {rmse}\")\n",
    "assert rmse == 1.2041594578792296"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3eqYonVJd8a"
   },
   "source": [
    "### $R^2$\n",
    "\n",
    "__Коэффициент детерминации $R^2$__ показывает долю дисперсии в целевой переменной, которая объяснена зависимыми переменными.   ($R^2$ можно интерпретировать как некоторого рода нормированное MSE).\n",
    "\n",
    "$$R^2(a, X, Y) = 1 - \\frac {\\sum^l_{i=1}(a(x_i) - y_i)^2}{\\sum^L_{i=1}(y_i - \\bar{y})^2}$$ или \n",
    "$$R^2(a, X, Y) = 1 - \\frac {\\frac{1}{l}\\sum^l_{i=1}(a(x_i) - y_i)^2}{\\frac{1}{l}\\sum^l_{i=1}(y_i - \\bar{y})^2},$$\n",
    "где \n",
    "$\\bar{y} = \\frac{1}{l}\\sum^l_{i=1}y_i$ - среднее значение целевой переменной.\n",
    "- Если $R^2 < 0$, значит наша модель даёт предсказание хуже константы, то есть абсолютно бесполезна с точки зрения MSE.\n",
    "- Если $R^2 = 0$, значит мы предсказываем не лучше и не хуже константы в виде среднего значения целевой переменной.\n",
    "- Если $0 < R^2 < 1$, значит модель работает лучше константного предсказания с точки зрения MSE.\n",
    "- Если $R^2 = 1$, значит ошибка MSE равна нулю. \n",
    "\n",
    "**Задание.** Реализуйте функцию для подсчета $R^2$ с использованием numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.768631Z",
     "start_time": "2023-03-01T13:28:20.763858Z"
    },
    "id": "KK3o7GozLjkV"
   },
   "outputs": [],
   "source": [
    "def R_squared(y: np.array, y_pred: np.array) -> np.float64:\n",
    "    # <YOUR CODE HERE>\n",
    "    std = ((y - np.mean(y))**2).mean()\n",
    "    return 1 - MSE(y,y_pred)/std\n",
    "\n",
    "\n",
    "r_squared = R_squared(y=a, y_pred=pred)\n",
    "print(f\"R2 score is: {r_squared}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альтернативный вариант (sklearn):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"r2_score is: {r2_score(a, pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa7c8WRk28lC"
   },
   "source": [
    "### MAE (Mean Absolute Error)\n",
    "\n",
    "$L(y_i, a(x_i)) = |a(x_i) - y_i|$\n",
    "\n",
    "__Средняя абсолютная ошибка (Mean Absolute Error, MAE)__:\n",
    "\n",
    "$$MAE(a, X) = \\frac {1}{l} \\sum^l_{i=1}|a(x_i) - y_i|$$\n",
    "\n",
    "В качестве альтернативы MSE можно использовать MAE. Ошибка MAE менее чувствительна к выбросам.\n",
    "\n",
    "**Задание.** Реализуйте функцию для подсчета MAE с использованием numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.874294Z",
     "start_time": "2023-03-01T13:28:20.771470Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eo-0TW82DzPw",
    "outputId": "f4e36fd7-9184-4ebb-e7f6-79e48d5c9124"
   },
   "outputs": [],
   "source": [
    "def MAE(y: np.array, y_pred: np.array) -> np.float64:\n",
    "    # <YOUR CODE HERE>\n",
    "    return np.abs(y-y_pred).mean()\n",
    "\n",
    "\n",
    "mae = MAE(y=a, y_pred=pred)\n",
    "print(f\"Mean Absolute Error is: {mae}\")\n",
    "assert mae == 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альтернативный вариант (sklearn):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MAE is: {mean_absolute_error(a, pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Можно обучить регрессию, оптимизируя MAE (а не MSE)</u>. В `sklearn` такая регрессия не реализована, но можно использовать модуль `statsmodels` (для работы со статистическими моделями). Более формально, необходимая модель может быть получена с помощью обучения <u>квантильной регрессии</u> с параметром `q=0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.874731Z",
     "start_time": "2023-03-01T13:28:20.776113Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/statsmodels/statsmodels \n",
    "#(если не работает импортирование библиотек ниже)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.890593Z",
     "start_time": "2023-03-01T13:28:20.780886Z"
    },
    "id": "PL2zqH8x28lD"
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf #синтаксис похож на R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:20.891333Z",
     "start_time": "2023-03-01T13:28:20.882087Z"
    },
    "id": "BFTTYeqY28lF"
   },
   "outputs": [],
   "source": [
    "def scatter_points_and_plot_line_MAE(\n",
    "    X_subset: np.array, ax: matplotlib.axes._axes.Axes\n",
    ") -> None:\n",
    "    # задаем зависимость переменной f15 от переменной f7 и передаем данные\n",
    "    mod = smf.quantreg(\"f15 ~ f7\", pd.DataFrame(data=X_subset, columns=[\"f7\", \"f15\"])) #квантильная регрессия \n",
    "    res = mod.fit(q=0.5) #q=0.5 - это минимизация MAE\n",
    "    \n",
    "    # визуализируем точки\n",
    "    ax.scatter(X_subset[:, 0], X_subset[:, 1])\n",
    " \n",
    "    # визуализируем прямую\n",
    "    grid = np.linspace(0, 2, 100)\n",
    "    line = grid * res.params[\"f7\"] + res.params[\"Intercept\"]\n",
    "    ax.plot(grid, line)\n",
    "    ax.set_ylim(-20, 100)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:21.225984Z",
     "start_time": "2023-03-01T13:28:20.890976Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ie_4TNdc28lH",
    "outputId": "85bcab8b-0876-4f52-98a7-87dc18beecdd"
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "ax[0].set_title(\"MAE without outliers\")\n",
    "scatter_points_and_plot_line_MAE(X_subset, ax[0])\n",
    "ax[1].set_title(\"MAE with outliers\")\n",
    "scatter_points_and_plot_line_MAE(X_subset_modified, ax[1])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWlsyGfu28lK"
   },
   "source": [
    "Прямая практически не изменила направление из-за выбросов! Попробуем добавить больше шумовых объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.randint(5, size=60).reshape(-1, 2)* [1, 30][:5]#поэлементное умножение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:21.229916Z",
     "start_time": "2023-03-01T13:28:21.227425Z"
    },
    "id": "RdDGJBER28lM"
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "X_subset_modified_twice = np.vstack(\n",
    "    (X_subset_modified, np.random.randint(5, size=60).reshape(-1, 2) * [1, 30])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:21.576038Z",
     "start_time": "2023-03-01T13:28:21.232487Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "McWJOOlN28lO",
    "outputId": "c44d54b7-7cda-4650-cf53-257573a82815"
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "ax[0].set_title(\"MAE without outliers\")\n",
    "scatter_points_and_plot_line_MAE(X_subset, ax[0])\n",
    "ax[1].set_title(\"MAE with outliers\")\n",
    "scatter_points_and_plot_line_MAE(X_subset_modified_twice, ax[1])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCq7zu_K28lQ"
   },
   "source": [
    "При таком количестве выбросов, изменилась даже регрессия над MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PMB5CGj28lR"
   },
   "source": [
    "### Оптимальные константы для MSE и MAE\n",
    "\n",
    "Допустим, все $l$ объектов выборки имеют одинаковые признаковые описания, но разные значения целевой переменной $y_1,...,y_l$. В этом случае модель должна на всех объектах выдать один и тот же ответ, т.е. алгоритм возвращает константное предсказание: $a(x) = C, C \\in R$.  \n",
    "\n",
    "**Задание.** Найдите $C$, минимизирующий среднеквадратичную ошибку.\n",
    "\n",
    "**Решение.** Нам необходимо найти константу C, минимизирующую функцию $\\frac{1}{n} \\sum_{i}^{n} (C - y_i)^2$. Для этого возьмём производную этой функции и приравняем её к нулю: $\\frac{2}{n}\\sum_{i}^{n} (C - y_i) = 0$. Преобразуем это выражение и выпишем ответ: $C = \\frac{\\sum_{i}^{n} y_i}{n}$. То есть <u>оптимальная константа</u> — <u>среднее значение целевой переменной</u>.\n",
    "\n",
    "**Задание.** Найдите $C$, минимизирующий среднюю абсолютную ошибку.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2jmXcciOl-K"
   },
   "source": [
    "## 4. Обучение линейных моделей\n",
    "\n",
    "Итак, $y$ - значение целевой переменной, $a$ — модель. \n",
    "\n",
    "$a(x_i)=  w_0+w_1x_i^1+...+w_dx_i^d$\n",
    "-- __линейная модель__,\n",
    "где $w_0, w_1,w_2,...,w_d$ -- веса признаков, $l$ - число объектов, $d$ - число признаков.\n",
    "\n",
    "__Линейная регрессия__ используется, когда целевая метка линейно зависит от признаков, возможно с каким-то шумом. Нередко линейная регрессия обучается с использованием среднеквадратичной ошибки.\n",
    "Другое название -  __метод наименьших квадратов, МНК__ - минимизация суммы квадратов разностей ответов $y_i$ и их приближений $a(x_i)$.\n",
    "\n",
    "Таким образом, получаем __задачу оптимизации__: требуется найти $w_0, w_1,...,w_d$ так, чтобы выполнялось условие:\n",
    "$$\n",
    "Q(a,X)=\\frac{1}{l}\\sum_{i=1}^{l}(y_i-a(x_i))^2\n",
    "\\rightarrow \\min_{w_0,w_1,...,w_d}\n",
    "$$\n",
    "или (будем считать, что среди признаков есть константный, и поэтому свободный коэффициент можно не писать):\n",
    "$$\n",
    "Q(w,X)=\n",
    "\\frac{1}{l}\\sum_{i=1}^{l}(<w,x_i>-y_i)^2\\rightarrow \\min_w\n",
    "$$\n",
    "или в матричной форме записи:\n",
    "$$\n",
    "Q(w,X)=\\frac{1}{l}\\|Xw-y\\|^2\\rightarrow \\min_{w}\n",
    "$$\n",
    "\n",
    "Дифференцируем $Q$ по параметрам $w_0,w_1,...,w_d$ и приравниваем к нулю, получаем:  \n",
    "$$ \n",
    "\\nabla_wQ(w,X)=\\frac{2}{l}X^T(Xw-y)=0\n",
    "$$\n",
    "Решив уравнение, получим аналитическое решение задачи линейной регрессии:\n",
    "$$\n",
    "w^*=(X^TX)^{-1}X^Ty\n",
    "$$\n",
    "\n",
    "(_Примечание. Для обучения модели на MSE константа $\\frac{1}{l}$ не очень важна, для оценки качества (после обучения) лучше усреднять_).\n",
    "\n",
    "Реализация линейной регрессии: `sklearn.linear_model.LinearRegression`.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частный случай: **парная регрессия**: $a(x)=  w_0+w_1x^1$, \n",
    "$$\n",
    "Q(w_0,w_1,X)=\n",
    "\\sum_{i=1}^{l}(w_1x_i^1+w_0-y_i)^2\\rightarrow \\min_{w_0,w_1}\n",
    "$$\n",
    "$\\frac{\\partial Q}{\\partial w_1}=2\\sum_{i=1}^{l}(w_1x_i^1+w_0-y_i)x_i^1$,\n",
    "\n",
    "$\\frac{\\partial Q}{\\partial w_0}=2\\sum_{i=1}^{l}(w_1x_i^1+w_0-y_i)$\n",
    "\n",
    "Выпишите формулы для $w_1$ и $w_0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1 (\"игрушечный\" пример)**. Предсказание линейной моделью (МНК) по трем признакам. (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)\n",
    "\n",
    "$y=3+ 1 \\cdot x_1 +2\\cdot x_2$ - искомая (приближаемая) функция (вообще говоря, неизвестна). Здесь номер индекса - это номер признака\n",
    "\n",
    "Дано:\n",
    "\n",
    "$X=\\begin{pmatrix}\n",
    "  1&1&1\\\\\n",
    "  1&1&2\\\\\n",
    "  1&2&2\\\\\n",
    "  1&2&3\\\\\n",
    "\\end{pmatrix}$ - матрица \"объект-признак\" (третий признак = 1 для всех объектов), \n",
    "$y=\\begin{pmatrix}\n",
    "  6\\\\\n",
    "  8\\\\\n",
    "  9\\\\\n",
    "  11\\\\\n",
    "\\end{pmatrix}\n",
    "$ - ответы\n",
    "\n",
    "Найти функцию $a(x)$, приближающую $y$: $a(x)=w_0 +w_1\\cdot x_1 +w_2\\cdot x_2 $\n",
    "\n",
    "Результат (обучения):\n",
    "\n",
    "$w=\\begin{pmatrix}\n",
    "  3\\\\\n",
    "  1\\\\\n",
    "  2\\\\\n",
    "\\end{pmatrix}\n",
    "$ - искомые веса,\n",
    "следовательно, $a(x)=3 +1\\cdot x_1 +2\\cdot x_2 $\n",
    "\n",
    "Применение полученной модели к новому объекту $x=(x_1, x_2)$:\n",
    "\n",
    "$a(x_1=3, x_2=5)=3+1 \\cdot 3 +2\\cdot 5=16$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Способ 1 (с помощью LinearRegression())**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1], \n",
    "              [1, 2], \n",
    "              [2, 2], \n",
    "              [2, 3]]) #признаки 4-х объектов\n",
    "print('X=',X)\n",
    "# y = 1 * x_0 + 2 * x_1 + 3 #\n",
    "y = np.dot(X, np.array([1, 2])) + 3  #целевая переменная\n",
    "print('y=',y)\n",
    "\n",
    "lr = LinearRegression() #создаем регрессор\n",
    "reg = lr.fit(X, y)    #обучение \n",
    "print('r2=',reg.score(X, y)) #the coefficient of determination of the prediction\n",
    "                       #(1 - \\frac{u}{v})`\n",
    "#1.0\n",
    "print('w1,w2=', reg.coef_)     #искомые параметры w1,w2 \n",
    "#array([1., 2.])\n",
    "print('w0=',reg.intercept_) #искомый параметр сдвиг w0\n",
    "#3.0...\n",
    "print('a([3, 5])=',reg.predict(np.array([[3, 5]]))) #предсказание для нового объекта x\n",
    "#array([16.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg.score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Способ 2: формула** $$\n",
    "w^*=(X^TX)^{-1}X^Ty\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "print('X=',X)\n",
    "\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "print('y=',y)\n",
    "\n",
    "X0 = np.array([[1], [1], [1], [1]])\n",
    "#print('X3=',X3)\n",
    "\n",
    "#X_mod = np.hstack([X, X3])\n",
    "X_mod = np.hstack([X0, X])\n",
    "print('X_mod=',X_mod)\n",
    "\n",
    "w= np.linalg.inv(X_mod.T@X_mod)@X_mod.T@y #формула w\n",
    "print('w=',w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 2 (парная регрессия)**. Предсказание линейной моделью (МНК) - на наборе данных по диабету. (https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "print(diabetes_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only one feature (столбец №2)\n",
    "diabetes_X = diabetes_X[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes_y[:-20]\n",
    "diabetes_y_test = diabetes_y[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test, color=\"black\")\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color=\"blue\", linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Линейная регрессия и переобучение \n",
    "### Данные о сообществах в США"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2jmXcciOl-K"
   },
   "source": [
    "\n",
    "\n",
    "Рассмортрим данные о сообществах в США. \n",
    "\n",
    "Предсказывается количество насильственных преступлений относительно численности населения.\n",
    "\n",
    "[Описание датасета](http://archive.ics.uci.edu/ml/datasets/communities+and+crime)\n",
    "[Датасет на кэггле](https://www.kaggle.com/kkanda/communities%20and%20crime%20unnormalized%20data%20set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:22.042689Z",
     "start_time": "2023-03-01T13:28:22.037079Z"
    },
    "id": "f3lmXNVFOx0G"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Смотрим на данные (без предобработки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"crimedata.csv\", na_values=[\"?\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставим лишь нужные колонки\n",
    "requiredColumns = [5, 6] + list(range(11, 26)) + list(range(32, 103)) + [145] #номера колонок\n",
    "data.columns[requiredColumns]  #названия этих колонок в датасете\n",
    "data = data[data.columns[requiredColumns]] #эти колонки в датасете\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# некоторые значения целевой переменной \"ViolentCrimesPerPop\" пропущены\n",
    "#выбираем строки, где нет пропусков в \"ViolentCrimesPerPop\"\n",
    "data.loc[data[\"ViolentCrimesPerPop\"].notnull(), :].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:22.134764Z",
     "start_time": "2023-03-01T13:28:22.046800Z"
    },
    "id": "PRft8CJyO1z8"
   },
   "outputs": [],
   "source": [
    "# матрица объект-признак (выбрасываем столбец \"ViolentCrimesPerPop\")\n",
    "X = data.loc[data[\"ViolentCrimesPerPop\"].notnull(), :].drop(\n",
    "    \"ViolentCrimesPerPop\", axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.index #индексы строк, которые вошли в X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#целевая переменная \"ViolentCrimesPerPop\" с индексами X\n",
    "y = data[\"ViolentCrimesPerPop\"][X.index] \n",
    "y.head()\n",
    "#y - похож на логнормальное распределение (гистограмма ниже) - можно так оставить \n",
    "# np.log1p(y) = log(1 + y) - уже нормальное распределение - или можно применить np.log1p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y); \n",
    "#plt.hist(np.log1p(y)) #можно применить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.log1p?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбиваем на train и test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#среднее значение (для инф-ии)\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCxXAdVtOiw4"
   },
   "source": [
    "### Baseline (\"стартовая точка\" - без предобработки)\n",
    "Обучим линейную регрессию и выведем качество по метрике MSE (RMSE) на обучающей и тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:22.135053Z",
     "start_time": "2023-03-01T13:28:22.085999Z"
    },
    "id": "ntYfZTzkQRAC"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression() #создаем регрессор\n",
    "lr.fit(X_train, y_train) #обучение\n",
    "\n",
    "pred_train = lr.predict(X_train) #предсказание\n",
    "pred_test = lr.predict(X_test)   #предсказание\n",
    "\n",
    "print(f\"Train: {mean_squared_error(y_train, pred_train)**0.5}\") #**0.5\n",
    "print(f\"Test: {mean_squared_error(y_test, pred_test)**0.5}\")    #**0.5\n",
    "\n",
    "r2_score(y_train, pred_train), r2_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#веса модели\n",
    "plt.hist(lr.coef_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr.coef_\n",
    "plt.plot(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Признаки переобучения__:\n",
    "- ошибка на test гораздо больше, чем ошибка на train\n",
    "- есть большие веса\n",
    "\n",
    "__Переобучение__ - явление, когда качество построенной модели на новых данных существенно хуже ее качества на обучающей выборке. То есть модель плохо обобщает результаты на новые объекты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd44Omp9TtcU"
   },
   "source": [
    "Популярным решением для регрессионных моделей является **регуляризация**.\n",
    "\n",
    "Во время оптимизации линейной регрессии, веса при переменных могут получиться большими в абсолютных значениях. Это не очень хорошо, поскольку модель будет чувствительна к крайне маленьким изменениям в признаках объекта, а значит, переобучена. Для решения проблемы к функционалу ошибки добавляют регуляризатор, который \"штрафует\" модель за слишком большую норму вектора весов:\n",
    "\n",
    "$$Q_\\alpha(w) = Q(w) + \\alpha R(w)$$ \n",
    "\n",
    "где $R(w)$ — __регуляризатор__, $\\alpha$ - __параметр регуляризации__ ($\\alpha \\geq 0$).\n",
    "\n",
    "Наиболее распространенными являются __L1 (Lasso)__ и __L2 (Ridge)__ регуляризаторы:\n",
    "$$L2: R(w) = ||w||_2^2 = \\sum^d_i w_i^2$$\n",
    "\n",
    "$$L1: R(w) = ||w||_1 = \\sum^d_i |w_i|$$\n",
    "\n",
    "Т.е. функционал ошибки $Q_\\alpha(w)$ в каждом из этих случаев будет иметь вид:\n",
    "\n",
    "$$L2: Q_\\alpha(w) = \\|Xw-y\\|^2\\ + \\alpha ||w||_2^2$$\n",
    "\n",
    "$$L1: Q_\\alpha(w) = \\|Xw-y\\|^2\\ + \\alpha ||w||_1$$\n",
    "\n",
    "Заметим, что оптимальный вектор весов в случае применения $L2$-регуляризации вместе со среднеквадратичной ошибкой имеет вид:\n",
    "\n",
    "$$\n",
    "w^*=(X^TX+\\alpha I)^{-1}X^Ty.\n",
    "$$\n",
    "\n",
    "Применим каждый из указанных регуляризаторов к нашей задаче и посмотрим на изменение в результатах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:22.246669Z",
     "start_time": "2023-03-01T13:28:22.109115Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RT8QZldbPqFr",
    "outputId": "126eb557-1c3d-4bdb-fe05-a4eb0adc1d76"
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(5.0).fit(X_train, y_train)\n",
    "print(\"Lasso\")\n",
    "print(f\"Train: {mean_squared_error(y_train, lasso.predict(X_train))**0.5}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, lasso.predict(X_test))**0.5}\")\n",
    "\n",
    "ridge = Ridge(5.0).fit(X_train, y_train)\n",
    "print(\"\\nRidge\")\n",
    "print(f\"Train: {mean_squared_error(y_train, ridge.predict(X_train))**0.5}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, ridge.predict(X_test))**0.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__При применении регуляризации всегда нужно масштабирование признаков__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzcwQ0T5QkRJ"
   },
   "source": [
    "### Scaling\n",
    "Попробуем MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:22.246880Z",
     "start_time": "2023-03-01T13:28:22.224569Z"
    },
    "id": "zedtNiBBQhOl"
   },
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "\n",
    "sc.fit(X_train)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(data=sc.transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(data=sc.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrldySniQ6jR"
   },
   "source": [
    "**Задание.** __Обучение линейной регрессии на масштабированных признаках и вывод ошибки на обучающей и тестовой выборках.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:22.327050Z",
     "start_time": "2023-03-01T13:28:22.239547Z"
    },
    "id": "PyoESXkkRQA1"
   },
   "outputs": [],
   "source": [
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression() #создаем регрессор\n",
    "lr.fit(X_train_scaled, y_train) #обучение\n",
    "\n",
    "pred_train = lr.predict(X_train_scaled) #предсказание\n",
    "pred_test = lr.predict(X_test_scaled)   #предсказание\n",
    "\n",
    "print(f\"Train: {mean_squared_error(y_train, pred_train)**0.5}\") #**0.5\n",
    "print(f\"Test: {mean_squared_error(y_test, pred_test)**0.5}\")    #**0.5\n",
    "\n",
    "r2_score(y_train, pred_train), r2_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkbwYrUdRSYR"
   },
   "source": [
    "**Задание:** __аналогично с добавлением Ridge регуляризации__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T13:28:22.328526Z",
     "start_time": "2023-03-01T13:28:22.257103Z"
    },
    "id": "YDELVx5FRh1F"
   },
   "outputs": [],
   "source": [
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(5.0).fit(X_train_scaled, y_train) #LinearRegression() - \n",
    "print(\"Lasso\")\n",
    "print(f\"Train: {mean_squared_error(y_train, lasso.predict(X_train_scaled))**0.5}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, lasso.predict(X_test_scaled))**0.5}\")\n",
    "\n",
    "ridge = Ridge(5.0).fit(X_train_scaled, y_train) #Ridge(10.0)\n",
    "print(\"\\nRidge\")\n",
    "print(f\"Train: {mean_squared_error(y_train, ridge.predict(X_train_scaled))**0.5}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, ridge.predict(X_test_scaled))**0.5}\")\n",
    "print()\n",
    "print('Train: {}, {}'.format(r2_score(y_train, lasso.predict(X_train_scaled)), r2_score(y_train, ridge.predict(X_train_scaled))))\n",
    "print('Test: {}, {}'.format(r2_score(y_test, lasso.predict(X_test_scaled)), r2_score(y_test, ridge.predict(X_test_scaled))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительно:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Отбор признаков на основе дисперсии (high/low variance)\n",
    "\n",
    "Полезны ли признаки, имеющие высокую дисперсию? А низкую? (и то, и то не очень хорошо) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.var().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#считаем дисперсию (по умолчанию нормируем на N-1, а не на N), сортируем по возрастанию (снизу вверх)\n",
    "features_variance = X_train_scaled.var().sort_values(ascending=False)\n",
    "features_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем удалить признаки с самой низкой дисперсией и посмотреть, как изменится качество. В sklearn есть специальный инструмент для такого отбора признаков. Стоит ли нормализовать перед этим признаки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно убрать все признаки, дисперсия которых меньше заданного значения\n",
    "vs_transformer = VarianceThreshold(0.01)\n",
    "vs_transformer.fit(X_train_scaled)\n",
    "data_train=vs_transformer.transform(X_train_scaled)\n",
    "data_test=vs_transformer.transform(X_test_scaled)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#булева маска выбранных признаков\n",
    "vs_transformer.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_var = pd.DataFrame(\n",
    "    data=data_train,\n",
    "    columns=X_train_scaled.columns[vs_transformer.get_support()],\n",
    ")\n",
    "X_train_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_var = pd.DataFrame(\n",
    "    data=data_test,\n",
    "    columns=X_test_scaled.columns[vs_transformer.get_support()],\n",
    ")\n",
    "\n",
    "X_test_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Было:\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#линейная регрессия\n",
    "lr = LinearRegression().fit(X_train_var, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, lr.predict(X_train_var))**0.5}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, lr.predict(X_test_var))**0.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L2-регуляризация\n",
    "ridge = Ridge(5.0).fit(X_train_var, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, ridge.predict(X_train_var))**0.5}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, ridge.predict(X_test_var))**0.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Отбор признаков на основе корреляции с целевой переменной (correlation)\n",
    "Можно выбрать k признаков, которые дают наиболее высокие значения корреляции с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем 15 лучших признаков (с т. зр. регрессионной задачи)\n",
    "sb = SelectKBest(f_regression, k=15)\n",
    "\n",
    "X_train_kbest = pd.DataFrame(\n",
    "    data=sb.fit_transform(X_train_var, y_train),\n",
    "    columns=X_train_var.columns[sb.get_support()],\n",
    ")\n",
    "X_test_kbest = pd.DataFrame(\n",
    "    data=sb.transform(X_test_var), columns=X_test_var.columns[sb.get_support()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train_kbest, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, lr.predict(X_train_kbest))**0.5}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, lr.predict(X_test_kbest))**0.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_kbest, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, ridge.predict(X_train_kbest))**0.5}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, ridge.predict(X_test_kbest))**0.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выбор самых значимых признаков с точки зрения регрессии с $L_1$-регуляризацией\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#отберем самые лучшие признаки с т.зр. lasso-регрессии\n",
    "lasso = Lasso(5.0)\n",
    "l1_select = SelectFromModel(lasso)\n",
    "\n",
    "X_train_l1 = pd.DataFrame(\n",
    "    data=l1_select.fit_transform(X_train_var, y_train),\n",
    "    columns=X_train_var.columns[l1_select.get_support()],\n",
    ")\n",
    "X_test_l1 = pd.DataFrame(\n",
    "    data=l1_select.transform(X_test_var),\n",
    "    columns=X_test_var.columns[l1_select.get_support()],\n",
    ")\n",
    "\n",
    "X_train_l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#используем отобранные по lasso признаки в лин. регрессии\n",
    "lr = LinearRegression().fit(X_train_l1, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, lr.predict(X_train_l1))**0.5}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, lr.predict(X_test_l1))**0.5}\")\n",
    "\n",
    "#используем отобранные по lasso признаки в лин. регрессии с ridge-регуляризацией\n",
    "ridge = Ridge(5.0).fit(X_train_l1, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, ridge.predict(X_train_l1))**0.5}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, ridge.predict(X_test_l1))**0.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Зададим все преобразования, отбор признаков и обучение при помощи Pipeline (поток)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#собираем все шаги (действия, которые мы использовали) вместе\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        (\"variance\", VarianceThreshold(0.01)),\n",
    "        (\"selection\", SelectFromModel(Lasso(5.0))),\n",
    "        (\"regressor\", Ridge(5.0)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train: {mean_squared_error(y_train, pipe.predict(X_train))**0.5}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, pipe.predict(X_test))**0.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Можно также настраивать параметры с помощью GridSearch (поиск по сетке):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"variance__threshold\": [0.005, 0.0075, 0.009, 0.01, 0.011, 0.012],\n",
    "    \"selection__estimator__alpha\": [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0],\n",
    "    \"regressor__alpha\": [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0],\n",
    "}\n",
    "#сюда помещаем pipe (все действия), param_grid (сетку), делаем кросс-валидацию \n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#лучшие подобранные параметры\n",
    "pipe_best = grid_search.best_estimator_\n",
    "pipe_best.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#обучение с лучшими параметрами, подобранными по сетке\n",
    "pipe_best.fit(X_train, y_train)\n",
    "print(f\"Train: {mean_squared_error(y_train, pipe_best.predict(X_train))**0.5}\")\n",
    "print(f\"Test: {mean_squared_error(y_test, pipe_best.predict(X_test))**0.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "sem06_linreg_unsolved.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
